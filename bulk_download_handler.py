"""
Ù…Ø§Ú˜ÙˆÙ„ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÙˆØ§Ø²ÛŒ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§

Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„ Ø§Ù…Ú©Ø§Ù† Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ø²Ù…Ø§Ù† Ú†Ù†Ø¯ÛŒÙ† Ù„ÛŒÙ†Ú© Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""

import os
import re
import asyncio
import logging
from typing import List, Dict, Optional, Set, Tuple
import time
import threading
import uuid
import json
from concurrent.futures import ThreadPoolExecutor

# ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯Ø±
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Ù…Ø­Ù„ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯
PENDING_DOWNLOADS_FILE = "pending_downloads.json"

# Ø­Ø¯Ø§Ú©Ø«Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† - Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§ÙØªÙ‡ Ø¨Ù‡ Ø´Ú©Ù„ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ú†Ù†Ø¯Ø¨Ø±Ø§Ø¨Ø±ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯
MAX_CONCURRENT_DOWNLOADS = 15

# ÙØ§ØµÙ„Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø¨ÛŒÙ† Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ (Ø¨Ù‡ Ø«Ø§Ù†ÛŒÙ‡) - Ø­Ø°Ù ØªÙ‚Ø±ÛŒØ¨ÛŒ ØªØ£Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ù‡Ù…Ø²Ù…Ø§Ù†
DOWNLOAD_DELAY = 0.1

# Ù…Ø¯ÛŒØ±ÛŒØª ØµÙ Ø¯Ø§Ù†Ù„ÙˆØ¯
download_queue = asyncio.Queue()
active_downloads = set()
download_results = {}
download_status = {}

# ØªÙ†Ø¸ÛŒÙ… Ø³Ù…Ø§ÙÙˆØ± Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù†
download_semaphore = asyncio.Semaphore(MAX_CONCURRENT_DOWNLOADS)

# Ù‚ÙÙ„ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ú¯Ø§Ù…â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø´ØªØ±Ú©
lock = threading.Lock()

class BulkDownloadManager:
    """Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡"""
    
    def __init__(self):
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡"""
        self.download_tasks = {}  # Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ØªØ³Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§
        self.load_pending_downloads()  # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø¹Ù„Ù‚
        
    def load_pending_downloads(self) -> None:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø¹Ù„Ù‚ Ø§Ø² ÙØ§ÛŒÙ„"""
        try:
            if os.path.exists(PENDING_DOWNLOADS_FILE):
                with open(PENDING_DOWNLOADS_FILE, 'r') as f:
                    self.pending_downloads = json.load(f)
                logger.info(f"ØªØ¹Ø¯Ø§Ø¯ {len(self.pending_downloads)} Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¹Ù„Ù‚ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            else:
                self.pending_downloads = {}
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø¹Ù„Ù‚: {str(e)}")
            self.pending_downloads = {}
    
    def save_pending_downloads(self) -> None:
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø¹Ù„Ù‚ Ø¯Ø± ÙØ§ÛŒÙ„"""
        try:
            with open(PENDING_DOWNLOADS_FILE, 'w') as f:
                json.dump(self.pending_downloads, f)
            logger.info(f"ØªØ¹Ø¯Ø§Ø¯ {len(self.pending_downloads)} Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¹Ù„Ù‚ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù…Ø¹Ù„Ù‚: {str(e)}")
    
    def extract_urls(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ URLâ€ŒÙ‡Ø§ÛŒ ÛŒÙˆØªÛŒÙˆØ¨ Ùˆ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… Ø§Ø² Ù…ØªÙ†"""
        # Ø§Ù„Ú¯ÙˆÛŒ URL Ù‡Ø§ÛŒ ÛŒÙˆØªÛŒÙˆØ¨
        youtube_pattern = r'(?:https?://)?(?:www\.)?(?:youtube\.com|youtu\.be)/(?:watch\?v=|shorts/)?([A-Za-z0-9_-]+)'
        # Ø§Ù„Ú¯ÙˆÛŒ URL Ù‡Ø§ÛŒ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù…
        instagram_pattern = r'(?:https?://)?(?:www\.)?instagram\.com/(?:p|reel)/([A-Za-z0-9_-]+)'
        
        # ØªØ±Ú©ÛŒØ¨ Ø§Ù„Ú¯ÙˆÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù‡Ø± Ø¯Ùˆ Ù†ÙˆØ¹ URL
        combined_pattern = f'{youtube_pattern}|{instagram_pattern}'
        
        matches = re.findall(combined_pattern, text)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ URLs Ú©Ø§Ù…Ù„
        urls = []
        
        # ÛŒØ§ÙØªÙ† ØªÙ…Ø§Ù… URLÙ‡Ø§ÛŒ ÛŒÙˆØªÛŒÙˆØ¨ Ø¯Ø± Ù…ØªÙ†
        youtube_matches = re.finditer(r'(?:https?://)?(?:www\.)?(?:youtube\.com|youtu\.be)/(?:watch\?v=|shorts/)?[A-Za-z0-9_-]+', text)
        for match in youtube_matches:
            urls.append(match.group())
            
        # ÛŒØ§ÙØªÙ† ØªÙ…Ø§Ù… URLÙ‡Ø§ÛŒ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… Ø¯Ø± Ù…ØªÙ†
        instagram_matches = re.finditer(r'(?:https?://)?(?:www\.)?instagram\.com/(?:p|reel)/[A-Za-z0-9_-]+', text)
        for match in instagram_matches:
            urls.append(match.group())
            
        return urls
    
    async def add_urls_to_queue(self, urls: List[str], user_id: int, quality: str = "best") -> str:
        """Ø§ÙØ²ÙˆØ¯Ù† Ú¯Ø±ÙˆÙ‡ÛŒ Ø§Ø² URLÙ‡Ø§ Ø¨Ù‡ ØµÙ Ø¯Ø§Ù†Ù„ÙˆØ¯"""
        if not urls:
            return "Ù‡ÛŒÚ† Ù„ÛŒÙ†Ú© Ù…Ø¹ØªØ¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯!"
            
        batch_id = f"batch_{uuid.uuid4().hex[:8]}"
        logger.info(f"Ø§ÙØ²ÙˆØ¯Ù† Ø¯Ø³ØªÙ‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù‡ {batch_id} Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id} Ø¨Ø§ {len(urls)} Ù„ÛŒÙ†Ú©")
        
        # Ø«Ø¨Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø³ØªÙ‡
        self.pending_downloads[batch_id] = {
            "urls": urls,
            "user_id": user_id,
            "quality": quality,
            "status": "pending",
            "progress": 0,
            "total": len(urls),
            "completed": 0,
            "timestamp": time.time()
        }
        
        self.save_pending_downloads()
        
        # Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡
        asyncio.create_task(self.process_batch(batch_id))
        
        return f"ğŸ”„ {len(urls)} Ù„ÛŒÙ†Ú© Ø¨Ù‡ ØµÙ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.\nâ³ Ø´Ù†Ø§Ø³Ù‡ Ø¯Ø³ØªÙ‡: `{batch_id}`\nØ§Ø² Ø¯Ø³ØªÙˆØ± /status_{batch_id} Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
    
    async def process_batch(self, batch_id: str) -> None:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© Ø¯Ø³ØªÙ‡ Ø§Ø² URLÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…ÙˆØ§Ø²ÛŒ"""
        if batch_id not in self.pending_downloads:
            logger.error(f"Ø´Ù†Ø§Ø³Ù‡ Ø¯Ø³ØªÙ‡ {batch_id} ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return
            
        batch = self.pending_downloads[batch_id]
        urls = batch["urls"]
        user_id = batch["user_id"]
        quality = batch["quality"]
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØ³Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯
        download_tasks = []
        
        self.pending_downloads[batch_id]["status"] = "processing"
        self.save_pending_downloads()
        
        # Ø§ÛŒØ¬Ø§Ø¯ ØªØ³Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ù…Ø§ÙÙˆØ± Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù†
        for i, url in enumerate(urls):
            download_task = asyncio.create_task(self.download_url_with_semaphore(url, user_id, quality, batch_id, i))
            download_tasks.append(download_task)
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ£Ø®ÛŒØ± Ø¨ÛŒÙ† Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ÙØ´Ø§Ø± Ø²ÛŒØ§Ø¯
            await asyncio.sleep(DOWNLOAD_DELAY)
        
        # Ù…Ù†ØªØ¸Ø± ØªÚ©Ù…ÛŒÙ„ ØªÙ…Ø§Ù… Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§
        await asyncio.gather(*download_tasks)
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø³ØªÙ‡
        self.pending_downloads[batch_id]["status"] = "completed"
        self.save_pending_downloads()
        
        logger.info(f"Ø¯Ø³ØªÙ‡ {batch_id} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯")
    
    async def download_url_with_semaphore(self, url: str, user_id: int, quality: str, batch_id: str, index: int) -> None:
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ URL Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ù…Ø§ÙÙˆØ± Ø¨Ø±Ø§ÛŒ Ú©Ù†ØªØ±Ù„ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù†"""
        async with download_semaphore:
            await self.download_url(url, user_id, quality, batch_id, index)
    
    async def download_url(self, url: str, user_id: int, quality: str, batch_id: str, index: int) -> None:
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÛŒÚ© URL Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ø§Ø³Ø¨ - Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±"""
        key = f"{batch_id}_{index}"
        try:
            logger.info(f"Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ {url} Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id} Ø¨Ø§ Ú©ÛŒÙÛŒØª {quality}")
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´
            download_status[key] = "downloading"
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¬Ø¯Ø¯
            from telegram_downloader import get_from_cache
            cached_file = get_from_cache(url, quality)
            if cached_file:
                logger.info(f"ÙØ§ÛŒÙ„ Ø§Ø² Ú©Ø´ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ø´Ø¯: {cached_file}")
                download_results[key] = cached_file
                download_status[key] = "completed"
                
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª
                with lock:
                    self.pending_downloads[batch_id]["completed"] += 1
                    self.pending_downloads[batch_id]["progress"] = (self.pending_downloads[batch_id]["completed"] / 
                                                                  self.pending_downloads[batch_id]["total"]) * 100
                    self.save_pending_downloads()
                return
            
            from telegram_downloader import InstagramDownloader, YouTubeDownloader, is_instagram_url, is_youtube_url, add_to_cache
            
            # Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø§Ù†Ù„ÙˆØ¯Ø± Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ URL
            if is_instagram_url(url):
                downloader = InstagramDownloader()
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ThreadPoolExecutor Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ 8 ØªØ±Ø¯ Ø¨Ø±Ø§ÛŒ Ú†Ù†Ø¯ Ø¨Ø±Ø§Ø¨Ø± Ú©Ø±Ø¯Ù† Ø³Ø±Ø¹Øª
                with ThreadPoolExecutor(max_workers=8) as executor:
                    # Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Ú†Ù†Ø¯ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§
                    downloaded_file = await asyncio.get_event_loop().run_in_executor(
                        executor,
                        lambda: asyncio.run(downloader.download_post(url, quality))
                    )
            elif is_youtube_url(url):
                downloader = YouTubeDownloader()
                # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú†Ù†Ø¯Ø¨Ø±Ø§Ø¨Ø± Ø³Ø±ÛŒØ¹â€ŒØªØ±
                youtube_opts = {
                    'concurrent_fragment_downloads': 20,
                    'buffersize': 1024 * 1024 * 50,
                    'http_chunk_size': 1024 * 1024 * 25,
                    'fragment_retries': 10,
                    'retry_sleep_functions': {'fragment': lambda x: 0.5},
                    'retries': 10,
                    'file_access_retries': 10,
                    'extractor_retries': 5,
                    'throttledratelimit': 0,
                    'sleep_interval': 0,
                    'max_sleep_interval': 0,
                    'external_downloader': 'aria2c',
                    'external_downloader_args': [
                        '-j', '16',
                        '-x', '16',
                        '-s', '16',
                        '--min-split-size=1M',
                        '--optimize-concurrent-downloads=true',
                        '--http-accept-gzip=true',
                        '--download-result=hide',
                        '--quiet=true',
                    ],
                }
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ThreadPoolExecutor Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ 8 ØªØ±Ø¯ Ø¨Ø±Ø§ÛŒ Ú†Ù†Ø¯ Ø¨Ø±Ø§Ø¨Ø± Ú©Ø±Ø¯Ù† Ø³Ø±Ø¹Øª
                with ThreadPoolExecutor(max_workers=8) as executor:
                    # Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Ú†Ù†Ø¯ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§
                    downloaded_file = await asyncio.get_event_loop().run_in_executor(
                        executor,
                        lambda: asyncio.run(downloader.download_video(url, quality))
                    )
            else:
                logger.warning(f"URL Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {url}")
                download_status[key] = "failed"
                
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ø¹Ù„ÛŒâ€ŒØ±ØºÙ… Ø®Ø·Ø§
                with lock:
                    self.pending_downloads[batch_id]["completed"] += 1
                    self.pending_downloads[batch_id]["progress"] = (self.pending_downloads[batch_id]["completed"] / 
                                                                  self.pending_downloads[batch_id]["total"]) * 100
                    self.save_pending_downloads()
                return
                
            # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯
            if downloaded_file:
                # Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ù‡ Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ
                add_to_cache(url, downloaded_file, quality)
                
                download_results[key] = downloaded_file
                download_status[key] = "completed"
                logger.info(f"Ø¯Ø§Ù†Ù„ÙˆØ¯ {url} Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id} ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯: {downloaded_file}")
            else:
                download_status[key] = "failed"
                logger.error(f"Ø¯Ø§Ù†Ù„ÙˆØ¯ {url} Ø¨Ø§ Ø´Ú©Ø³Øª Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ (ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ø®Ø§Ù„ÛŒ)")
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ø¯Ø³ØªÙ‡
            with lock:
                self.pending_downloads[batch_id]["completed"] += 1
                self.pending_downloads[batch_id]["progress"] = (self.pending_downloads[batch_id]["completed"] / 
                                                               self.pending_downloads[batch_id]["total"]) * 100
                self.save_pending_downloads()
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ {url}: {str(e)}")
            download_status[key] = "failed"
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ø¯Ø³ØªÙ‡ Ø¹Ù„ÛŒâ€ŒØ±ØºÙ… Ø®Ø·Ø§
            with lock:
                self.pending_downloads[batch_id]["completed"] += 1
                self.pending_downloads[batch_id]["progress"] = (self.pending_downloads[batch_id]["completed"] / 
                                                               self.pending_downloads[batch_id]["total"]) * 100
                self.save_pending_downloads()
    
    async def get_batch_status(self, batch_id: str) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª ÛŒÚ© Ø¯Ø³ØªÙ‡ Ø¯Ø§Ù†Ù„ÙˆØ¯"""
        if batch_id in self.pending_downloads:
            return self.pending_downloads[batch_id]
        return {"error": "Ø´Ù†Ø§Ø³Ù‡ Ø¯Ø³ØªÙ‡ ÛŒØ§ÙØª Ù†Ø´Ø¯"}
    
    def get_download_file(self, batch_id: str, index: int) -> Optional[str]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡"""
        key = f"{batch_id}_{index}"
        if key in download_results:
            return download_results[key]
        return None
        
    def get_all_batches_for_user(self, user_id: int) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø±"""
        user_batches = []
        for batch_id, batch in self.pending_downloads.items():
            if batch.get("user_id") == user_id:
                batch_info = batch.copy()
                batch_info["batch_id"] = batch_id
                user_batches.append(batch_info)
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù† (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ø§ÙˆÙ„)
        user_batches.sort(key=lambda x: x.get("timestamp", 0), reverse=True)
        return user_batches

# Ù†Ù…ÙˆÙ†Ù‡ Ø³ÛŒÙ†Ú¯Ù„ØªÙˆÙ† Ø§Ø² Ù…Ø¯ÛŒØ± Ø¯Ø§Ù†Ù„ÙˆØ¯
download_manager = BulkDownloadManager()

# ØªØ¹Ø±ÛŒÙ Ø¯Ø³ØªÙˆØ±Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÙˆØ§Ø²ÛŒ
async def handle_bulk_download(update, context):
    """Ù‡Ù†Ø¯Ù„Ø± Ø¯Ø³ØªÙˆØ± /bulkdownload Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡"""
    message_text = update.message.text
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©ÛŒÙÛŒØª Ø§Ø² Ø¯Ø³ØªÙˆØ±
    quality_match = re.search(r'/bulkdownload\s+(\w+)', message_text)
    quality = "best"
    if quality_match:
        requested_quality = quality_match.group(1).lower()
        if requested_quality in ["1080p", "720p", "480p", "360p", "240p", "audio"]:
            quality = requested_quality
    
    # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¯Ø³ØªÙˆØ± Ø§Ø² Ù…ØªÙ†
    message_text = re.sub(r'/bulkdownload\s+\w+\s*', '', message_text)
    message_text = re.sub(r'/bulkdownload\s*', '', message_text)
    
    if not message_text and update.message.reply_to_message:
        # Ø§Ú¯Ø± Ø¯Ø³ØªÙˆØ± Ø¯Ø± Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ù¾ÛŒØ§Ù… Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø³ØªØŒ Ø§Ø² Ù…ØªÙ† Ø¢Ù† Ù¾ÛŒØ§Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        message_text = update.message.reply_to_message.text
    
    if not message_text:
        await update.message.reply_text(
            "âš ï¸ Ù„Ø·ÙØ§Ù‹ Ú†Ù†Ø¯ Ù„ÛŒÙ†Ú© ÛŒÙˆØªÛŒÙˆØ¨ ÛŒØ§ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… Ø±Ø§ Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø§ÛŒÙ† Ø¯Ø³ØªÙˆØ± Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ù‡ Ù¾ÛŒØ§Ù…ÛŒ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§Ø³Øª Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯.\n\n"
            "Ù…Ø«Ø§Ù„:\n"
            "/bulkdownload 720p\n"
            "https://www.youtube.com/watch?v=ABC123\n"
            "https://www.instagram.com/p/DEF456\n"
            "https://www.youtube.com/shorts/GHI789"
        )
        return
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
    urls = download_manager.extract_urls(message_text)
    
    if not urls:
        await update.message.reply_text("âŒ Ù‡ÛŒÚ† Ù„ÛŒÙ†Ú© Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± Ù¾ÛŒØ§Ù… Ø´Ù…Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return
    
    # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´
    processing_message = await update.message.reply_text(
        f"ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ {len(urls)} Ù„ÛŒÙ†Ú©... Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯."
    )
    
    # Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ù‡ ØµÙ Ø¯Ø§Ù†Ù„ÙˆØ¯
    result = await download_manager.add_urls_to_queue(urls, update.effective_user.id, quality)
    
    # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒØ§Ù…
    await processing_message.edit_text(result)

async def handle_batch_status(update, context):
    """Ù‡Ù†Ø¯Ù„Ø± Ø¯Ø³ØªÙˆØ± /status_{batch_id} Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø³ØªÙ‡ Ø¯Ø§Ù†Ù„ÙˆØ¯"""
    message_text = update.message.text
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ù†Ø§Ø³Ù‡ Ø¯Ø³ØªÙ‡ Ø§Ø² Ø¯Ø³ØªÙˆØ±
    batch_id_match = re.search(r'/status_(\w+)', message_text)
    if not batch_id_match:
        await update.message.reply_text("âŒ Ù„Ø·ÙØ§Ù‹ Ø´Ù†Ø§Ø³Ù‡ Ø¯Ø³ØªÙ‡ Ø±Ø§ Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø¯Ø³ØªÙˆØ± ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯. Ù…Ø«Ø§Ù„: /status_batch_abc123")
        return
    
    batch_id = batch_id_match.group(1)
    
    # Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ø¯Ø³ØªÙ‡
    status = await download_manager.get_batch_status(batch_id)
    
    if "error" in status:
        await update.message.reply_text(f"âŒ {status['error']}")
        return
    
    # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… ÙˆØ¶Ø¹ÛŒØª
    progress = status.get("progress", 0)
    completed = status.get("completed", 0)
    total = status.get("total", 0)
    current_status = status.get("status", "Ù†Ø§Ù…Ø´Ø®Øµ")
    
    # ØªØ±Ø¬Ù…Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
    status_translation = {
        "pending": "Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø±",
        "processing": "Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´",
        "completed": "ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡"
    }
    
    persian_status = status_translation.get(current_status, current_status)
    
    # Ø³Ø§Ø®Øª Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª
    progress_bar = make_progress_bar(progress)
    
    message = (
        f"ğŸ“Š ÙˆØ¶Ø¹ÛŒØª Ø¯Ø³ØªÙ‡ Ø¯Ø§Ù†Ù„ÙˆØ¯: `{batch_id}`\n\n"
        f"ğŸ”„ ÙˆØ¶Ø¹ÛŒØª: {persian_status}\n"
        f"âœ… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡: {completed} Ø§Ø² {total}\n"
        f"â³ Ù¾ÛŒØ´Ø±ÙØª: {progress:.1f}%\n\n"
        f"{progress_bar}\n\n"
    )
    
    # Ø§Ú¯Ø± Ø¯Ø³ØªÙ‡ Ú©Ø§Ù…Ù„ Ø´Ø¯Ù‡ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ù†Ø´Ø§Ù† Ø¨Ø¯Ù‡
    if current_status == "completed":
        message += "âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡ Ø§Ø³Øª. ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯."
    
    await update.message.reply_text(message)

async def handle_list_downloads(update, context):
    """Ù‡Ù†Ø¯Ù„Ø± Ø¯Ø³ØªÙˆØ± /mydownloads Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù‡Ù…Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±"""
    user_id = update.effective_user.id
    
    # Ø¯Ø±ÛŒØ§ÙØª Ù‡Ù…Ù‡ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±
    batches = download_manager.get_all_batches_for_user(user_id)
    
    if not batches:
        await update.message.reply_text("âŒ Ø´Ù…Ø§ Ù‡ÛŒÚ† Ø¯Ø³ØªÙ‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ÛŒ Ù†Ø¯Ø§Ø±ÛŒØ¯.")
        return
    
    # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ù„ÛŒØ³Øª Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§
    message = "ğŸ“‹ Ù„ÛŒØ³Øª Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ù…Ø§:\n\n"
    
    for i, batch in enumerate(batches, 1):
        batch_id = batch.get("batch_id", "Ù†Ø§Ù…Ø´Ø®Øµ")
        progress = batch.get("progress", 0)
        status = batch.get("status", "Ù†Ø§Ù…Ø´Ø®Øµ")
        total = batch.get("total", 0)
        timestamp = batch.get("timestamp", 0)
        
        # ØªØ±Ø¬Ù…Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
        status_translation = {
            "pending": "Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø±",
            "processing": "Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´",
            "completed": "ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡"
        }
        
        persian_status = status_translation.get(status, status)
        
        # ØªØ¨Ø¯ÛŒÙ„ timestamp Ø¨Ù‡ ØªØ§Ø±ÛŒØ® Ø®ÙˆØ§Ù†Ø§
        date_str = time.strftime("%Y-%m-%d %H:%M", time.localtime(timestamp))
        
        message += (
            f"{i}. Ø´Ù†Ø§Ø³Ù‡: `{batch_id}`\n"
            f"   ğŸ“Š ÙˆØ¶Ø¹ÛŒØª: {persian_status} ({progress:.1f}%)\n"
            f"   ğŸ“ ØªØ¹Ø¯Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: {total}\n"
            f"   ğŸ•’ ØªØ§Ø±ÛŒØ®: {date_str}\n"
            f"   ğŸ“ Ø¯Ø³ØªÙˆØ± Ø¨Ø±Ø±Ø³ÛŒ: `/status_{batch_id}`\n\n"
        )
    
    await update.message.reply_text(message)

def make_progress_bar(percent, length=20):
    """Ø³Ø§Ø®Øª Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª Ù…ØªÙ†ÛŒ"""
    filled_length = int(length * percent / 100)
    bar = 'â–ˆ' * filled_length + 'â–‘' * (length - filled_length)
    return f"[{bar}] {percent:.1f}%"

def register_handlers(application):
    """Ø«Ø¨Øª Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ø¯Ø³ØªÙˆØ±Ø§Øª Ø¯Ø± Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† ØªÙ„Ú¯Ø±Ø§Ù…"""
    from telegram.ext import CommandHandler, MessageHandler, filters
    
    # Ù‡Ù†Ø¯Ù„Ø± Ø¯Ø³ØªÙˆØ± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡
    application.add_handler(CommandHandler("bulkdownload", handle_bulk_download))
    
    # Ù‡Ù†Ø¯Ù„Ø± Ø¯Ø³ØªÙˆØ± Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¨Ø§ Ø§Ù„Ú¯ÙˆÛŒ /status_{batch_id}
    application.add_handler(MessageHandler(filters.Regex(r'^/status_\w+'), handle_batch_status))
    
    # Ù‡Ù†Ø¯Ù„Ø± Ø¯Ø³ØªÙˆØ± Ù†Ù…Ø§ÛŒØ´ Ù‡Ù…Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§
    application.add_handler(CommandHandler("mydownloads", handle_list_downloads))
    
    logger.info("Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø«Ø¨Øª Ø´Ø¯Ù†Ø¯")